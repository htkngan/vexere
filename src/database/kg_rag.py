import sys
import os

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from config.settings import config
import re
import json

# Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i tá»« thÆ° má»¥c gá»‘c
document_text_path = "src/database/docs/vexere_policy_structured.txt"
faq_data_path = "src/database/docs/vexere_support_data.json"

def create_semantic_chunks(text):
    """
    HÃ m nÃ y chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n (chunks) dá»±a trÃªn cÃ¡c tiÃªu Ä‘á» (##).
    Má»—i chunk sáº½ chá»©a ná»™i dung dÆ°á»›i má»™t tiÃªu Ä‘á» vÃ  metadata lÃ  chÃ­nh tiÃªu Ä‘á» Ä‘Ã³.
    """
    parts = re.split(r'(## .*)', text)
    chunks = []
    metadatas = []
    current_heading = "Giá»›i thiá»‡u chung"

    if parts[0].strip() == "":
        parts = parts[1:]

    for i in range(len(parts)):
        part = parts[i].strip()
        if part.startswith("##"):
            current_heading = part.replace("##", "").strip()
        elif part:
            cleaned_text = re.sub(r'ğŸ“„', '', part).strip()
            cleaned_text = re.sub(r'\s{2,}', ' ', cleaned_text)
            chunks.append(cleaned_text)
            metadatas.append({"source": current_heading})
            
    return chunks, metadatas

def policy_kg():
    """Khá»Ÿi táº¡o knowledge graph tá»« file policy"""
    if not os.path.exists(document_text_path):
        print(f"File khÃ´ng tá»“n táº¡i: {document_text_path}")
        return
        
    with open(document_text_path, "r", encoding="utf-8") as file:
        document_text = file.read()

    chunks, metadatas = create_semantic_chunks(document_text)

    print(f"ÄÃ£ táº¡o ra {len(chunks)} Ä‘oáº¡n vÄƒn báº£n (chunks).")

    print("\nÄang táº£i mÃ´ hÃ¬nh embedding 'Alibaba-NLP/gte-multilingual-base'...")
    # LÆ¯U Ã: Láº§n Ä‘áº§u tiÃªn cháº¡y, quÃ¡ trÃ¬nh táº£i mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt.
    # trust_remote_code=True lÃ  báº¯t buá»™c Ä‘á»ƒ mÃ´ hÃ¬nh nÃ y hoáº¡t Ä‘á»™ng.
    model = config.model
    print("MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c táº£i.")

    # Táº¡o embeddings cho táº¥t cáº£ cÃ¡c chunks
    print("Äang táº¡o embeddings cho cÃ¡c chunks...")
    embeddings = model.encode(chunks, show_progress_bar=True)
    print(f"ÄÃ£ táº¡o xong {len(embeddings)} embeddings.")

    ids = [f"chunk_{i}" for i in range(len(chunks))]

    # ThÃªm dá»¯ liá»‡u vÃ o collection
    config.collection.add(
        embeddings=embeddings,
        documents=chunks,
        metadatas=metadatas,
        ids=ids
    )

    print(f"ÄÃ£ thÃªm thÃ nh cÃ´ng {config.collection.count()} tÃ i liá»‡u vÃ o ChromaDB.")

def faq_kg():
    """Táº£i FAQ knowledge graph"""
    if not os.path.exists(faq_data_path):
        print(f"File FAQ khÃ´ng tá»“n táº¡i: {faq_data_path}")
        return {}
        
    with open(faq_data_path, "r", encoding="utf-8") as file:
        faq_data = json.load(file)
    
    # Lá»c ra cÃ¡c FAQ cÃ³ content
    faq_data = {
        key: value for key, value in faq_data.items() 
        if value.get('content') and len(value['content']) > 0
    }

    return faq_data